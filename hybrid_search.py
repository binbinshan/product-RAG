"""
Module 2: Hybrid SearchæœåŠ¡
èŒè´£: åŸºäºæ”¹å†™Queryæ‰§è¡Œå‘é‡+å…³é”®è¯+ç»“æ„åŒ–è¿‡æ»¤çš„å¹¶è¡Œæ£€ç´¢
"""
import numpy as np
import os
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
from pymilvus import Collection, connections
from dotenv import load_dotenv
from index_builder import ProductDatabase, HybridIndexBuilder
from models import (
    VectorRetrievalInput, VectorRetrievalResult,
    KeywordRetrievalInput, KeywordRetrievalResult,
    MergedCandidate, RetrievalLog, RetrievalLogSummary
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class VectorRetrievalService:
    """å‘é‡æ£€ç´¢å­æ¨¡å— - åŸºäºé¢„æ„å»ºç´¢å¼•"""

    def __init__(self, index_data: Optional[Dict[str, Any]] = None, embedding_model: Optional[str] = None):
        self.db = ProductDatabase()
        # ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼
        model_name = embedding_model or os.getenv('EMBEDDING_MODEL', 'all-MiniLM-L6-v2')
        self.encoder = SentenceTransformer(model_name)

        if index_data is None:
            # å¦‚æœæ²¡æœ‰æä¾›ç´¢å¼•æ•°æ®ï¼Œåˆ™æ„å»ºæ–°çš„
            builder = HybridIndexBuilder(embedding_model)
            indices = builder.build_all_indices()
            self.index_data = indices["vector_index"]
        else:
            self.index_data = index_data

        self.use_fallback = self.index_data["index_type"] == "memory"
        self._setup_index()

    def _setup_index(self):
        """è®¾ç½®ç´¢å¼•"""
        self.sku_list = self.index_data["sku_list"]
        self.content_list = self.index_data["content_list"]
        self.product_map = self.index_data["product_map"]

        if self.use_fallback:
            self.embeddings = self.index_data["embeddings"]
        else:
            # é‡æ–°è¿æ¥Milvus
            try:
                self.collection = Collection(self.index_data["collection_name"])
                self.collection.load()
                print("Milvusç´¢å¼•åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"Milvusè¿æ¥å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å†…å­˜ç´¢å¼•: {e}")
                self.use_fallback = True
                # éœ€è¦é‡æ–°æ„å»ºå†…å­˜ç´¢å¼•
                embeddings = self.encoder.encode(self.content_list)
                self.embeddings = np.array(embeddings).astype('float32')

    def retrieve(self, input_data: VectorRetrievalInput) -> List[VectorRetrievalResult]:
        """
        æ‰§è¡Œå‘é‡æ£€ç´¢ - ä½¿ç”¨Pre-Filteringé¿å…å¬å›ç©ºç™½

        Args:
            input_data: å‘é‡æ£€ç´¢è¾“å…¥

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # æŸ¥è¯¢å‘é‡ç¼–ç 
        query_vector = self.encoder.encode([input_data.query])
        query_vector = np.array(query_vector).astype('float32')

        if self.use_fallback:
            # å…ˆè¿›è¡Œè¿‡æ»¤
            filtered_products = self.db.filter_products(input_data.filters)
            filtered_skus = {p["sku_id"] for p in filtered_products}
            return self._fallback_retrieve(query_vector[0], filtered_skus, input_data.top_k)

        try:
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šPre-Filtering - æ„å»ºMilvus exprè¡¨è¾¾å¼
            expr = self._build_milvus_expr(input_data.filters)

            # Milvusæ£€ç´¢ - ä½¿ç”¨exprè¿›è¡ŒPre-Filtering
            search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
            results = self.collection.search(
                data=[query_vector[0].tolist()],
                anns_field="embedding",
                param=search_params,
                limit=input_data.top_k,  # ç›´æ¥å–éœ€è¦çš„æ•°é‡ï¼Œä¸éœ€è¦*2
                expr=expr  # ğŸ”¥ Pre-Filteringå…³é”®å‚æ•°
            )

            # æ„å»ºç»“æœ - ä¸éœ€è¦åç½®è¿‡æ»¤
            final_results = []
            for hit in results[0]:
                sku_id = hit.entity.get("sku_id")
                content = hit.entity.get("content")

                # Milvusè¿”å›çš„æ˜¯è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                score = 1.0 / (1.0 + float(hit.distance))

                final_results.append(VectorRetrievalResult(
                    sku_id=sku_id,
                    score=score,
                    content=content
                ))

            return final_results

        except Exception as e:
            print(f"Milvusæ£€ç´¢å¤±è´¥ï¼Œé™çº§åˆ°å†…å­˜ç´¢å¼•: {e}")
            # é™çº§æ—¶ä»éœ€è¿‡æ»¤
            filtered_products = self.db.filter_products(input_data.filters)
            filtered_skus = {p["sku_id"] for p in filtered_products}
            return self._fallback_retrieve(query_vector[0], filtered_skus, input_data.top_k)

    def _build_milvus_expr(self, filters: Dict[str, Any]) -> Optional[str]:
        """
        æ„å»ºMilvusè¡¨è¾¾å¼ç”¨äºPre-Filtering

        Args:
            filters: è¿‡æ»¤æ¡ä»¶å­—å…¸

        Returns:
            Milvusè¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰è¿‡æ»¤æ¡ä»¶åˆ™è¿”å›None
        """
        if not filters:
            return None

        expr_parts = []

        # æ³¨æ„ï¼šè¿™é‡Œçš„å­—æ®µåéœ€è¦ä¸index_builder.pyä¸­Milvus schemaä¸€è‡´
        # ç›®å‰schemaä¸­åªæœ‰ id, sku_id, embedding, content å­—æ®µ
        # æ‰€ä»¥åªèƒ½åŸºäºsku_idè¿›è¡Œè¿‡æ»¤

        # å…ˆè·å–ç¬¦åˆæ¡ä»¶çš„å•†å“SKUåˆ—è¡¨
        filtered_products = self.db.filter_products(filters)
        if not filtered_products:
            # å¦‚æœæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å•†å“ï¼Œè¿”å›ç©ºç»“æœçš„è¡¨è¾¾å¼
            return "sku_id in ['__EMPTY__']"

        sku_list = [p["sku_id"] for p in filtered_products]

        # æ„å»ºSKU INè¡¨è¾¾å¼
        if len(sku_list) > 0:
            # Milvusçš„INè¡¨è¾¾å¼æ ¼å¼: field in [value1, value2, ...]
            sku_str = "', '".join(sku_list)
            expr_parts.append(f"sku_id in ['{sku_str}']")

        return " and ".join(expr_parts) if expr_parts else None

    def _fallback_retrieve(self, query_vector: np.ndarray, filtered_skus: set, top_k: int) -> List[VectorRetrievalResult]:
        """
        é™çº§æ£€ç´¢æ–¹æ³• - ä¿®å¤OOMé£é™©

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            filtered_skus: è¿‡æ»¤åçš„SKUé›†åˆ
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        try:
            # ğŸ”¥ ä¿®å¤é—®é¢˜5: OOMé˜²æŠ¤ - æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
            embeddings_size_mb = self.embeddings.nbytes / (1024 * 1024)
            if embeddings_size_mb > 1024:  # è¶…è¿‡1GBçš„embeddingçŸ©é˜µ
                print(f"è­¦å‘Šï¼šå‘é‡çŸ©é˜µè¿‡å¤§({embeddings_size_mb:.1f}MB)ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³")
                # å¦‚æœçŸ©é˜µè¿‡å¤§ï¼Œåªå¤„ç†è¿‡æ»¤åçš„å•†å“
                return self._memory_safe_fallback(query_vector, filtered_skus, top_k)

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            scores = np.dot(self.embeddings, query_vector) / (
                np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_vector)
            )

            # è·å–top-kç´¢å¼•
            top_indices = np.argsort(scores)[::-1][:top_k * 2]

            results = []
            for idx in top_indices:
                sku_id = self.sku_list[idx]

                if sku_id not in filtered_skus:
                    continue

                results.append(VectorRetrievalResult(
                    sku_id=sku_id,
                    score=float(scores[idx]),
                    content=self.content_list[idx]
                ))

                if len(results) >= top_k:
                    break

            return results

        except MemoryError as e:
            print(f"å†…å­˜ä¸è¶³é”™è¯¯: {e}ï¼Œä½¿ç”¨å®‰å…¨æ¨¡å¼æ£€ç´¢")
            return self._memory_safe_fallback(query_vector, filtered_skus, top_k)

    def _memory_safe_fallback(self, query_vector: np.ndarray, filtered_skus: set, top_k: int) -> List[VectorRetrievalResult]:
        """
        å†…å­˜å®‰å…¨çš„é™çº§æ£€ç´¢æ–¹æ³•
        """
        # åªè®¡ç®—è¿‡æ»¤åSKUçš„ç›¸ä¼¼åº¦ï¼Œé¿å…å…¨é‡è®¡ç®—
        filtered_indices = []
        for i, sku_id in enumerate(self.sku_list):
            if sku_id in filtered_skus:
                filtered_indices.append(i)

        if not filtered_indices:
            return []

        # åªæå–éœ€è¦çš„embeddingè¿›è¡Œè®¡ç®—
        filtered_embeddings = self.embeddings[filtered_indices]
        scores = np.dot(filtered_embeddings, query_vector) / (
            np.linalg.norm(filtered_embeddings, axis=1) * np.linalg.norm(query_vector)
        )

        # æ’åºå¹¶è¿”å›ç»“æœ
        sorted_indices = np.argsort(scores)[::-1][:top_k]

        results = []
        for i in sorted_indices:
            original_idx = filtered_indices[i]
            results.append(VectorRetrievalResult(
                sku_id=self.sku_list[original_idx],
                score=float(scores[i]),
                content=self.content_list[original_idx]
            ))

        return results


class KeywordRetrievalService:
    """å…³é”®è¯æ£€ç´¢å­æ¨¡å— - åŸºäºé¢„æ„å»ºç´¢å¼•"""

    # ğŸ”¥ ä¿®å¤é—®é¢˜5: ç±»çº§åˆ«jiebaå®ä¾‹ï¼Œé¿å…é‡å¤åˆå§‹åŒ–å†…å­˜æµªè´¹
    _jieba_instance = None

    @classmethod
    def _get_jieba(cls):
        """è·å–å•ä¾‹jiebaå®ä¾‹"""
        if cls._jieba_instance is None:
            import jieba
            cls._jieba_instance = jieba
        return cls._jieba_instance

    def __init__(self, index_data: Optional[Dict[str, Any]] = None):
        self.jieba = self._get_jieba()
        self.db = ProductDatabase()

        if index_data is None:
            # å¦‚æœæ²¡æœ‰æä¾›ç´¢å¼•æ•°æ®ï¼Œåˆ™æ„å»ºæ–°çš„
            builder = HybridIndexBuilder()
            indices = builder.build_all_indices()
            self.index_data = indices["keyword_index"]
        else:
            self.index_data = index_data

        self._setup_index()

    def _setup_index(self):
        """è®¾ç½®ç´¢å¼•"""
        self.sku_list = self.index_data["sku_list"]
        self.product_map = self.index_data["product_map"]
        self.bm25 = self.index_data["bm25"]

    def retrieve(self, input_data: KeywordRetrievalInput) -> List[KeywordRetrievalResult]:
        """
        æ‰§è¡Œå…³é”®è¯æ£€ç´¢ - ä¼˜åŒ–æ€§èƒ½ç“¶é¢ˆï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œ

        Args:
            input_data: å…³é”®è¯æ£€ç´¢è¾“å…¥

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # è¿‡æ»¤å•†å“
        filtered_products = self.db.filter_products(input_data.filters)
        filtered_skus = {p["sku_id"] for p in filtered_products}

        # BM25æ£€ç´¢
        query_text = " ".join(input_data.keywords).lower()
        query_tokens = list(self.jieba.cut(query_text))
        scores = self.bm25.get_scores(query_tokens)

        # ğŸ”¥ ä¿®å¤é—®é¢˜3: ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œï¼Œé¿å…PythonåŸç”Ÿå¾ªç¯
        scores_array = np.array(scores)
        sku_array = np.array(self.sku_list)

        # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šåªå¤„ç†åˆ†æ•°>0çš„å•†å“ï¼Œé¿å…å…¨é‡è¿­ä»£
        positive_mask = scores_array > 0
        positive_indices = np.where(positive_mask)[0]

        if len(positive_indices) == 0:
            return []

        # æå–éé›¶åˆ†æ•°å’Œå¯¹åº”çš„SKU
        positive_scores = scores_array[positive_indices]
        positive_skus = sku_array[positive_indices]

        # ğŸ”¥ å‘é‡åŒ–è¿‡æ»¤ï¼šä½¿ç”¨é›†åˆäº¤é›†æ“ä½œæ›¿ä»£é€ä¸ªæ£€æŸ¥
        # åˆ›å»ºSKUåˆ°ç´¢å¼•çš„æ˜ å°„ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾
        filtered_sku_indices = []
        filtered_scores = []

        for idx, sku_id in enumerate(positive_skus):
            if sku_id in filtered_skus:
                filtered_sku_indices.append(positive_indices[idx])
                filtered_scores.append(positive_scores[idx])

        if not filtered_scores:
            return []

        # ğŸ”¥ å‘é‡åŒ–æ’åºï¼šä½¿ç”¨NumPy argsortæ›¿ä»£Python sort
        sorted_indices = np.argsort(filtered_scores)[::-1]  # é™åºæ’åº

        # æ„å»ºç»“æœ
        results = []
        max_candidates = int(os.getenv('MAX_CANDIDATES', '50'))

        for i in sorted_indices[:max_candidates]:
            original_idx = filtered_sku_indices[i]
            results.append(KeywordRetrievalResult(
                sku_id=self.sku_list[original_idx],
                score=float(filtered_scores[i])
            ))

        return results


class HybridSearchService:
    """Hybrid SearchæœåŠ¡ - å¤šè·¯å¬å›"""

    def __init__(self, vector_service: Optional[VectorRetrievalService] = None,
                 keyword_service: Optional[KeywordRetrievalService] = None,
                 embedding_model: Optional[str] = None):
        """
        åˆå§‹åŒ–æ··åˆæœç´¢æœåŠ¡

        Args:
            vector_service: å‘é‡æ£€ç´¢æœåŠ¡å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°çš„
            keyword_service: å…³é”®è¯æ£€ç´¢æœåŠ¡å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°çš„
            embedding_model: å‘é‡æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
        """
        if vector_service is None or keyword_service is None:
            # ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼
            model_name = embedding_model or os.getenv('EMBEDDING_MODEL', 'all-MiniLM-L6-v2')

            # æ„å»ºç´¢å¼•æ•°æ®
            builder = HybridIndexBuilder(model_name)
            indices = builder.build_all_indices()

            self.vector_service = vector_service or VectorRetrievalService(
                indices["vector_index"], model_name
            )
            self.keyword_service = keyword_service or KeywordRetrievalService(
                indices["keyword_index"]
            )
        else:
            self.vector_service = vector_service
            self.keyword_service = keyword_service

    def search(self, rewritten_queries: List[str], filters: Dict[str, Any], enable_logging: bool = True) -> List[MergedCandidate]:
        """
        æ‰§è¡Œæ··åˆæ£€ç´¢

        Args:
            rewritten_queries: æ”¹å†™åçš„æŸ¥è¯¢åˆ—è¡¨
            filters: è¿‡æ»¤æ¡ä»¶
            enable_logging: æ˜¯å¦å¯ç”¨å¬å›æ—¥å¿—

        Returns:
            åˆå¹¶åçš„å€™é€‰å•†å“åˆ—è¡¨
        """
        candidates_map: Dict[str, MergedCandidate] = {}

        # å­˜å‚¨æ‰€æœ‰å‘é‡æ£€ç´¢ç»“æœï¼Œç”¨äºç”Ÿæˆæ—¥å¿—
        all_vector_results: Dict[str, List[tuple]] = {}  # query -> [(sku_id, score, rank)]
        all_keyword_results: List[tuple] = []  # [(sku_id, score, rank)]

        # 1. å‘é‡æ£€ç´¢ - å¯¹æ¯ä¸ªæ”¹å†™æŸ¥è¯¢
        vector_top_k = int(os.getenv('VECTOR_TOP_K', '20'))
        for query in rewritten_queries:
            vector_input = VectorRetrievalInput(
                query=query,
                top_k=vector_top_k,
                filters=filters
            )
            vector_results = self.vector_service.retrieve(vector_input)

            # è®°å½•å‘é‡æ£€ç´¢ç»“æœç”¨äºæ—¥å¿—
            if enable_logging:
                all_vector_results[query] = [(result.sku_id, result.score, i+1) for i, result in enumerate(vector_results)]

            for result in vector_results:
                if result.sku_id not in candidates_map:
                    candidates_map[result.sku_id] = MergedCandidate(
                        sku_id=result.sku_id,
                        vector_score=result.score,
                        keyword_score=0.0,
                        sources=["vector"],
                        content=result.content
                    )
                else:
                    # å–æœ€é«˜åˆ†
                    if result.score > candidates_map[result.sku_id].vector_score:
                        candidates_map[result.sku_id].vector_score = result.score
                    if "vector" not in candidates_map[result.sku_id].sources:
                        candidates_map[result.sku_id].sources.append("vector")

        # 2. å…³é”®è¯æ£€ç´¢
        # æå–æ‰€æœ‰å…³é”®è¯
        all_keywords = []
        for query in rewritten_queries:
            all_keywords.extend(query.split())
        all_keywords = list(set(all_keywords))  # å»é‡

        if all_keywords:
            keyword_input = KeywordRetrievalInput(
                keywords=all_keywords,
                filters=filters
            )
            keyword_results = self.keyword_service.retrieve(keyword_input)

            # è®°å½•å…³é”®è¯æ£€ç´¢ç»“æœç”¨äºæ—¥å¿—
            if enable_logging:
                keyword_query = " ".join(all_keywords)
                all_keyword_results = [(result.sku_id, result.score, i+1) for i, result in enumerate(keyword_results)]

            for result in keyword_results:
                if result.sku_id not in candidates_map:
                    candidates_map[result.sku_id] = MergedCandidate(
                        sku_id=result.sku_id,
                        vector_score=0.0,
                        keyword_score=result.score,
                        sources=["keyword"],
                        content=""
                    )
                else:
                    candidates_map[result.sku_id].keyword_score = result.score
                    if "keyword" not in candidates_map[result.sku_id].sources:
                        candidates_map[result.sku_id].sources.append("keyword")

        # 3. è®¡ç®—æ··åˆåˆ†æ•°å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
        candidates = list(candidates_map.values())
        candidates = self._calculate_hybrid_scores(candidates)

        # 4. ç”Ÿæˆå¬å›æ—¥å¿—
        if enable_logging:
            candidates = self._generate_retrieval_logs(
                candidates,
                all_vector_results,
                all_keyword_results,
                " ".join(all_keywords) if all_keywords else ""
            )

        return candidates

    def _calculate_hybrid_scores(self, candidates: List[MergedCandidate]) -> List[MergedCandidate]:
        """
        è®¡ç®—æ··åˆæ£€ç´¢èåˆåˆ†æ•° - ä¿®å¤å½’ä¸€åŒ–ç®—æ³•ç¼ºé™·

        Args:
            candidates: å€™é€‰å•†å“åˆ—è¡¨

        Returns:
            æ·»åŠ äº†fusion_scoreçš„å€™é€‰å•†å“åˆ—è¡¨
        """
        # ä»ç¯å¢ƒå˜é‡è·å–æƒé‡é…ç½®
        vector_weight = float(os.getenv('VECTOR_WEIGHT', '0.7'))
        keyword_weight = float(os.getenv('KEYWORD_WEIGHT', '0.3'))

        # æƒé‡å½’ä¸€åŒ–ï¼ˆç¡®ä¿å’Œä¸º1ï¼‰
        total_weight = vector_weight + keyword_weight
        if total_weight > 0:
            vector_weight = vector_weight / total_weight
            keyword_weight = keyword_weight / total_weight
        else:
            vector_weight, keyword_weight = 0.7, 0.3

        # ğŸ”¥ ä¿®å¤é—®é¢˜2: åˆ†æ•°å½’ä¸€åŒ–ç®—æ³•ç¼ºé™·
        vector_scores = [c.vector_score or 0.0 for c in candidates]
        keyword_scores = [c.keyword_score or 0.0 for c in candidates]

        # ğŸ”¥ å…³é”®ä¿®å¤A: åªå¯¹éé›¶å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œé¿å…0å€¼å¹²æ‰°
        # å‘é‡åˆ†æ•°å½’ä¸€åŒ–
        non_zero_vector = [s for s in vector_scores if s > 0]
        if len(non_zero_vector) > 1 and max(non_zero_vector) > min(non_zero_vector):
            min_v, max_v = min(non_zero_vector), max(non_zero_vector)
            vector_scores = [(s - min_v) / (max_v - min_v) if s > 0 else 0.0 for s in vector_scores]
        else:
            # å¦‚æœåªæœ‰ä¸€ä¸ªæˆ–å…¨éƒ¨ç›¸åŒçš„éé›¶å€¼ï¼Œç›´æ¥è®¾ä¸º1.0
            vector_scores = [1.0 if s > 0 else 0.0 for s in vector_scores]

        # ğŸ”¥ å…³é”®ä¿®å¤B: BM25åˆ†æ•°ä½¿ç”¨Sigmoidå½’ä¸€åŒ–ï¼Œé¿å…å¼‚å¸¸å€¼é—®é¢˜
        non_zero_keyword = [s for s in keyword_scores if s > 0]
        if non_zero_keyword:
            # ä½¿ç”¨Sigmoidå‡½æ•°å¤„ç†BM25åˆ†æ•°ï¼Œæ›´ç¨³å®š
            import math
            # å°†åˆ†æ•°æ˜ å°„åˆ°[0,1]åŒºé—´ï¼Œé¿å…æå€¼å¹²æ‰°
            max_bm25 = max(non_zero_keyword)
            normalized_keyword = []
            for s in keyword_scores:
                if s > 0:
                    # ä½¿ç”¨æ”¹è¿›çš„sigmoid: 1 / (1 + exp(-x/k)), å…¶ä¸­kä¸ºç¼©æ”¾å› å­
                    k = max_bm25 / 6  # ç¼©æ”¾å› å­ï¼Œä½¿å¾—æœ€å¤§å€¼çº¦ä¸º0.95
                    normalized = 1 / (1 + math.exp(-s / max(k, 0.1)))
                    normalized_keyword.append(normalized)
                else:
                    normalized_keyword.append(0.0)
            keyword_scores = normalized_keyword
        else:
            keyword_scores = [0.0 for _ in keyword_scores]

        # ğŸ”¥ ä¿®å¤é—®é¢˜4: ç»Ÿä¸€ä½¿ç”¨é…ç½®çš„æƒé‡å…¬å¼ï¼Œæ¶ˆé™¤Magic Numbers
        for i, candidate in enumerate(candidates):
            # ç»Ÿä¸€çš„åŠ æƒèåˆå…¬å¼ï¼Œä¸å†æœ‰ç¡¬ç¼–ç çš„0.8/0.2
            candidate.hybrid_score = vector_scores[i] * vector_weight + keyword_scores[i] * keyword_weight

        # æŒ‰èåˆåˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x.hybrid_score or 0.0, reverse=True)

        return candidates

    def _generate_retrieval_logs(self, candidates: List[MergedCandidate],
                                 all_vector_results: Dict[str, List[tuple]],
                                 all_keyword_results: List[tuple],
                                 keyword_query: str) -> List[MergedCandidate]:
        """
        ç”Ÿæˆå¬å›æ—¥å¿—

        Args:
            candidates: å€™é€‰å•†å“åˆ—è¡¨
            all_vector_results: å‘é‡æ£€ç´¢ç»“æœ {query: [(sku_id, score, rank)]}
            all_keyword_results: å…³é”®è¯æ£€ç´¢ç»“æœ [(sku_id, score, rank)]
            keyword_query: å…³é”®è¯æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            æ·»åŠ äº†å¬å›æ—¥å¿—çš„å€™é€‰å•†å“åˆ—è¡¨
        """
        from datetime import datetime

        for candidate in candidates:
            logs = []

            # ç”Ÿæˆå‘é‡æ£€ç´¢æ—¥å¿—
            vector_queries = []
            vector_hits = 0
            max_vector_score = 0.0

            for query, results in all_vector_results.items():
                for sku_id, score, rank in results:
                    if sku_id == candidate.sku_id:
                        logs.append(RetrievalLog(
                            query=query,
                            retrieval_type="vector",
                            score=score,
                            normalized_score=None,  # å°†åœ¨åé¢è®¾ç½®
                            rank=rank,
                            timestamp=datetime.now()
                        ))
                        vector_queries.append(query)
                        vector_hits += 1
                        max_vector_score = max(max_vector_score, score)
                        break

            # ç”Ÿæˆå…³é”®è¯æ£€ç´¢æ—¥å¿—
            keyword_queries = []
            keyword_hits = 0
            max_keyword_score = 0.0

            for sku_id, score, rank in all_keyword_results:
                if sku_id == candidate.sku_id:
                    logs.append(RetrievalLog(
                        query=keyword_query,
                        retrieval_type="keyword",
                        score=score,
                        normalized_score=None,  # å°†åœ¨åé¢è®¾ç½®
                        rank=rank,
                        timestamp=datetime.now()
                    ))
                    keyword_queries.append(keyword_query)
                    keyword_hits += 1
                    max_keyword_score = max(max_keyword_score, score)
                    break

            # è®¾ç½®å½’ä¸€åŒ–åˆ†æ•°
            for log in logs:
                if log.retrieval_type == "vector" and candidate.vector_score:
                    log.normalized_score = candidate.vector_score
                elif log.retrieval_type == "keyword" and candidate.keyword_score:
                    log.normalized_score = candidate.keyword_score

            # ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
            candidate.retrieval_logs = logs
            candidate.log_summary = RetrievalLogSummary(
                total_queries=len(all_vector_results) + (1 if keyword_query else 0),
                vector_queries=list(set(vector_queries)),
                keyword_queries=list(set(keyword_queries)),
                vector_hits=vector_hits,
                keyword_hits=keyword_hits,
                max_vector_score=max_vector_score if max_vector_score > 0 else None,
                max_keyword_score=max_keyword_score if max_keyword_score > 0 else None,
                final_rank=None  # å°†åœ¨è¿”å›æ’åºåçš„åˆ—è¡¨æ—¶è®¾ç½®
            )

        # è®¾ç½®æœ€ç»ˆæ’å
        for i, candidate in enumerate(candidates, 1):
            if candidate.log_summary:
                candidate.log_summary.final_rank = i

        return candidates

    def print_retrieval_logs(self, candidates: List[MergedCandidate], top_n: int = 5):
        """
        æ‰“å°å¬å›æ—¥å¿—

        Args:
            candidates: å€™é€‰å•†å“åˆ—è¡¨
            top_n: æ˜¾ç¤ºå‰Nä¸ªå€™é€‰å•†å“çš„æ—¥å¿—
        """
        print(f"\n=== å¬å›æ—¥å¿—è¯¦æƒ… (Top {top_n}) ===")

        for i, candidate in enumerate(candidates[:top_n], 1):
            print(f"\nã€ç¬¬ {i} åã€‘SKU: {candidate.sku_id}")
            print(f"  æœ€ç»ˆåˆ†æ•°: {candidate.hybrid_score:.4f} (å‘é‡: {candidate.vector_score or 0:.4f}, å…³é”®è¯: {candidate.keyword_score or 0:.4f})")
            print(f"  å¬å›æ¥æº: {', '.join(candidate.sources)}")

            if candidate.log_summary:
                summary = candidate.log_summary
                print(f"  å¬å›æ±‡æ€»:")
                print(f"    æ€»æŸ¥è¯¢æ•°: {summary.total_queries}")
                print(f"    å‘é‡å‘½ä¸­: {summary.vector_hits}æ¬¡, å…³é”®è¯å‘½ä¸­: {summary.keyword_hits}æ¬¡")
                if summary.max_vector_score:
                    print(f"    æœ€é«˜å‘é‡åˆ†æ•°: {summary.max_vector_score:.4f}")
                if summary.max_keyword_score:
                    print(f"    æœ€é«˜å…³é”®è¯åˆ†æ•°: {summary.max_keyword_score:.4f}")

            if candidate.retrieval_logs:
                print(f"  æ£€ç´¢è¯¦æƒ…:")
                for j, log in enumerate(candidate.retrieval_logs, 1):
                    print(f"    {j}. [{log.retrieval_type}] \"{log.query}\" -> åˆ†æ•°: {log.score:.4f}, æ’å: #{log.rank}")

            print("-" * 80)

    def __call__(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        LangGraphèŠ‚ç‚¹è°ƒç”¨æ¥å£

        Args:
            input_data: çŠ¶æ€å­—å…¸

        Returns:
            æ›´æ–°åçš„çŠ¶æ€å­—å…¸
        """
        rewritten_queries = input_data.get("rewritten_queries", [])
        filters = input_data.get("filters", {})

        candidates = self.search(rewritten_queries, filters)

        return {
            "candidates": candidates
        }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("åˆå§‹åŒ–æ£€ç´¢æœåŠ¡...")
    hybrid_service = HybridSearchService()

    print("\næµ‹è¯•æ··åˆæ£€ç´¢:")
    candidates = hybrid_service.search(
        rewritten_queries=["ä½ä¹³ç³– å„¿ç«¥ å¥¶ç²‰", "ç›Šç”ŸèŒ é…æ–¹å¥¶ç²‰"],
        filters={"category": "å¥¶ç²‰", "status": "ON_SALE"},
        enable_logging=True
    )

    print(f"\næ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰å•†å“:")
    for c in candidates[:5]:
        print(f"  SKU: {c.sku_id}, å‘é‡åˆ†æ•°: {c.vector_score:.3f}, å…³é”®è¯åˆ†æ•°: {c.keyword_score:.3f}, æ··åˆåˆ†æ•°: {c.hybrid_score:.3f}, æ¥æº: {c.sources}")

    # æ˜¾ç¤ºå¬å›æ—¥å¿—
    hybrid_service.print_retrieval_logs(candidates, top_n=3)